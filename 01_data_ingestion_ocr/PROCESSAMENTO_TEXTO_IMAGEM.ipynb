{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuração Inicial e Instalação de Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mathe\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy -q\n",
    "!pip install python-dotenv -q\n",
    "!pip install requests -q\n",
    "!pip install opencv-python -q\n",
    "!pip install opencv-python-headless -q\n",
    "!pip install google-cloud-storage -q\n",
    "!pip install google-cloud-bigquery -q\n",
    "!pip install pandas-gbq google-cloud-bigquery pyarrow -q\n",
    "!pip install pandas-gbq --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Credenciais e Variáveis de Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caminho da chave de serviço configurado via os.environ.\n"
     ]
    }
   ],
   "source": [
    "# Célula de Inicialização de Variáveis e Credenciais\n",
    "\n",
    "# 1. Carrega todas as variáveis do arquivo .env para o ambiente\n",
    "load_dotenv(r\"C:\\Users\\mathe\\Downloads\\archive (10)\\.env.txt\")\n",
    "\n",
    "# 2. Garante que o caminho da chave de serviço (ADC)\n",
    "\n",
    "chave_path = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "if chave_path:\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = chave_path\n",
    "    print(\"Caminho da chave de serviço configurado via os.environ.\")\n",
    "else:\n",
    "    print(\"Atenção: GOOGLE_APPLICATION_CREDENTIALS não foi encontrado no .env!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puxar os valores das variáveis de ambiente\n",
    "bucket_name = os.getenv(\"GCP_BUCKET_NAME\")\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "\n",
    "# Configuracoes adicionais\n",
    "prefix = \"\"\n",
    "dataset_id = \"processamento_imagens\"\n",
    "table_id = \"dados-imagens-processadas\"\n",
    "x, y, w, h = 182, 322, 877, 1026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Definição de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Google Cloud Storage (GCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_imagens_bucket(bucket_name, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Listar os objetos (imagens) em um bucket do Google Cloud Storage.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "    return [blob.name for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def baixar_imagem_bucket(bucket_name, imagem_nome):\n",
    "    \"\"\"\n",
    "    Fazer o download de uma imagem do bucket do Google Cloud Storage.\n",
    "    \"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(imagem_nome)\n",
    "    return np.asarray(bytearray(blob.download_as_bytes()), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. BigQuery (Controle de Processamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_imagem_processada(image_name):\n",
    "    \"\"\"\n",
    "    Verificar se a imagem já foi processada consultando o BigQuery.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    query = f\"\"\"\n",
    "        SELECT COUNT(*) as count\n",
    "        FROM `{project_id}.{dataset_id}.{table_id}`\n",
    "        WHERE image_name = @image_name\n",
    "    \"\"\"\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"image_name\", \"STRING\", image_name)\n",
    "        ]\n",
    "    )\n",
    "    query_job = client.query(query, job_config=job_config)\n",
    "    results = query_job.result()\n",
    "    for row in results:\n",
    "        return row.count > 0\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def registrar_imagem_processada(image_name):\n",
    "    \"\"\"\n",
    "    Registrar uma imagem como processada no BigQuery.\n",
    "    \"\"\"\n",
    "    client = bigquery.Client(project=project_id)\n",
    "    table_ref = client.dataset(dataset_id).table(table_id)\n",
    "    table = client.get_table(table_ref)\n",
    "    rows_to_insert = [\n",
    "        {\"image_name\": image_name, \"processed_date\": datetime.utcnow().isoformat()}\n",
    "    ]\n",
    "    errors = client.insert_rows_json(table, rows_to_insert)\n",
    "    if errors:\n",
    "        raise RuntimeError(f\"Erro ao inserir no BigQuery: {errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Pré-processamento de Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para recortar a área de interesse\n",
    "def extrair_etiqueta(img, x, y, w, h):\n",
    "    \"\"\"\n",
    "    Recorta a região da etiqueta usando as coordenadas.\n",
    "    \"\"\"\n",
    "    etiqueta = img[y:y + h, x:x + w]  \n",
    "    return etiqueta\n",
    "\n",
    "# Carregar uma nova imagem\n",
    "imagem = cv2.imread('cropped_image.jpg')\n",
    "\n",
    "if imagem is not None:\n",
    "    # Recortar a etiqueta\n",
    "    etiqueta = extrair_etiqueta(imagem, x, y, w, h)\n",
    "\n",
    "    # Mostrar e salvar o recorte\n",
    "    cv2.imwrite(\"etiqueta_recortada.jpg\", etiqueta)\n",
    "else:\n",
    "    print(\"Erro: Não foi possível carregar a imagem. Verifique o caminho ou o arquivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. OCR (Google Vision API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocrGoogleVisionApi(imagem):\n",
    "    \n",
    "    # 1. PEGAR A CHAVE DA API DA VARIÁVEL DE AMBIENTE\n",
    "    api_key = os.getenv(\"GOOGLE_VISION_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        return \"Erro: A chave 'GOOGLE_VISION_API_KEY' não foi encontrada nas variáveis de ambiente.\"\n",
    "\n",
    "    # Codificar a imagem em base64\n",
    "    _, buffer = cv2.imencode('.jpg', imagem)\n",
    "    my_base64 = base64.b64encode(buffer).decode(\"utf-8\") \n",
    "\n",
    "    # 2. USAR A CHAVE NA URL\n",
    "    # URL da API com a chave de API\n",
    "    url = f'https://vision.googleapis.com/v1/images:annotate?key={api_key}'\n",
    "\n",
    "    # Dados do pedido\n",
    "    data = {\n",
    "        \"requests\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"content\": my_base64\n",
    "                },\n",
    "                \"features\": [\n",
    "                    {\"type\": \"TEXT_DETECTION\"}\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Enviar o pedido POST\n",
    "    r = requests.post(url=url, data=json.dumps(data), headers={\"Content-Type\": \"application/json\"})\n",
    "\n",
    "    # Verificar se houve erro\n",
    "    if r.status_code != 200:\n",
    "        return \"Erro: \" + r.text\n",
    "\n",
    "    # Extrair as anotações de texto\n",
    "    texts = r.json()['responses'][0].get('textAnnotations', [])\n",
    "\n",
    "    # Coletar os resultados\n",
    "    results = [t['description'] for t in texts]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Tratamento de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento dos dados\n",
    "\n",
    "# Pré-compila todos os padrões\n",
    "PADRAO_VALIDADE = re.compile(\n",
    "    r'(?:Val(?:\\.|idade)?[:\\s]*)'                \n",
    "    r'(?P<validade>\\d{2}/\\d{4}|\\d{2}/\\d{2}/\\d{4})',\n",
    "    re.IGNORECASE\n",
    ")\n",
    "PADRAO_CODIGO = re.compile(r'Cod[:\\s]*(?P<codigo>[\\w\\.-]+)', re.IGNORECASE)\n",
    "PADRAO_LOTE   = re.compile(r'Lote[:\\s]*(?P<lote>\\d+)',             re.IGNORECASE)\n",
    "PADRAO_VOLUME = re.compile(r'Cont[.\\s:]*?(?P<volume>\\d+(?:L|mL))', re.IGNORECASE)\n",
    "\n",
    "def extrair_dados(texto_fragmentos):\n",
    "    # 1) Monta string única, limpa quebras de linha\n",
    "    texto = ' '.join(texto_fragmentos).replace('\\n', ' ').replace('\\r', ' ')\n",
    "\n",
    "    resultados = {\n",
    "        'validade': None,\n",
    "        'codigo_produto': None,\n",
    "        'lote': None,\n",
    "        'volume': None,\n",
    "    }\n",
    "\n",
    "    # 2) Busca validade e valida\n",
    "    m = PADRAO_VALIDADE.search(texto)\n",
    "    if m:\n",
    "        val = m.group('validade')\n",
    "        # se veio no formato MM/YYYY, assume dia = 01\n",
    "        to_parse = val if val.count('/') == 2 else f\"01/{val}\"\n",
    "        try:\n",
    "            dt = datetime.strptime(to_parse, '%d/%m/%Y')\n",
    "            resultados['validade'] = dt.strftime('%d/%m/%Y')\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    # 3) Código do produto\n",
    "    m = PADRAO_CODIGO.search(texto)\n",
    "    if m:\n",
    "        resultados['codigo_produto'] = m.group('codigo')\n",
    "\n",
    "    # 4) Lote (só aceita dígitos)\n",
    "    m = PADRAO_LOTE.search(texto)\n",
    "    if m and int(m.group('lote')) > 0:\n",
    "        resultados['lote'] = m.group('lote')\n",
    "\n",
    "    # 5) Volume (ex.: 18L ou 100mL)\n",
    "    m = PADRAO_VOLUME.search(texto)\n",
    "    if m:\n",
    "        vol = m.group('volume')\n",
    "        num = int(re.match(r'\\d+', vol).group())\n",
    "        if num > 0:\n",
    "            resultados['volume'] = vol\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execução do Processamento Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagem já processada: cropped_2.jpeg\n",
      "Imagem já processada: cropped_image.jpg\n",
      "Imagem já processada: tinta_luxens.JPG\n"
     ]
    }
   ],
   "source": [
    "dados_extraidos = []\n",
    "\n",
    "# Processo principal\n",
    "try:\n",
    "    imagens = listar_imagens_bucket(bucket_name, prefix)\n",
    "    for nova_imagem in imagens:\n",
    "        if not verificar_imagem_processada(nova_imagem):\n",
    "            print(f\"Processando nova imagem: {nova_imagem}\")\n",
    "\n",
    "            imagem_bytes = baixar_imagem_bucket(bucket_name, nova_imagem)\n",
    "            imagem_original = cv2.imdecode(np.frombuffer(imagem_bytes, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            if imagem_original is None:\n",
    "                raise ValueError(\"Erro ao decodificar a imagem baixada.\")\n",
    "\n",
    "            etiqueta_recortada = extrair_etiqueta(imagem_original, x, y, w, h)\n",
    "            texto_extraido = ocrGoogleVisionApi(etiqueta_recortada)\n",
    "            print(\"Texto extraído:\", texto_extraido)\n",
    "\n",
    "            #  Tratar o texto sujo com regex logo após o OCR\n",
    "            dados = extrair_dados(texto_extraido)\n",
    "            print(\" Dados extraídos:\", dados)\n",
    "\n",
    "            dados_extraidos.append({\n",
    "                'imagem': nova_imagem,\n",
    "                'validade': dados['validade'],\n",
    "                'codigo_produto': dados['codigo_produto'],\n",
    "                'lote': dados['lote'],\n",
    "                'volume': dados['volume']\n",
    "            })\n",
    "\n",
    "            registrar_imagem_processada(nova_imagem)\n",
    "        else:\n",
    "            print(f\"Imagem já processada: {nova_imagem}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro ao processar a imagem: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Insert de Dados no BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Criação do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(dados_extraidos)\n\u001b[0;32m      2\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dados_extraidos)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Gravação no BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_gbq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchallenge-421602\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tabela de métricas\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mto_gbq\u001b[49m(\n\u001b[0;32m      9\u001b[0m     df,\n\u001b[0;32m     10\u001b[0m     destination_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessamento_imagens.texto_extraido\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m     project_id\u001b[38;5;241m=\u001b[39mproject_id,\n\u001b[0;32m     12\u001b[0m     if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_gbq' is not defined"
     ]
    }
   ],
   "source": [
    "# Gravar dados na tabela do big query\n",
    "\n",
    "\n",
    "# ID do projeto\n",
    "project_id = 'challenge-421602'\n",
    "\n",
    "# Tabela de métricas\n",
    "to_gbq(\n",
    "    df,\n",
    "    destination_table='processamento_imagens.texto_extraido',\n",
    "    project_id=project_id,\n",
    "    if_exists='append' \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
